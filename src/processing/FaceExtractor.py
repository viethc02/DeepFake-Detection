# -*- coding: utf-8 -*-
"""Processing_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pi4hZgM6pGkSnHBXeKKNxoZLDmQrST_p
"""

# from google.colab import drive
# drive.mount('/content/drive')

# import os
# os.chdir('drive/MyDrive/DeepFake')

# !pip install facenet-pytorch

import cv2
import matplotlib.pyplot as plt
from facenet_pytorch import MTCNN
import torch
import numpy as np
from PIL import Image, ImageDraw
from IPython import display
import glob

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

device

def read_video(path):
  frames = []
  cap = cv2.VideoCapture(path)
  max_frames = 32
  frame_count = 0
  while True:
    ret, frame = cap.read()
    #print(frame)
    if not ret:
        break
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frames.append(frame)
    frame_count += 1
    if frame_count == max_frames:
        break
  cap.release()
  return frames

def detect_faces(frames):
  face_detector = MTCNN(margin=0, device=device)
  frames_tracked = []
  for i, frame in enumerate(frames):
    print('\rTracking frame: {}'.format(i + 1), end='')

    # Detect faces
    boxes, probs = face_detector.detect(frame)
    # Draw faces
    frame_draw = frame.copy()
    id = np.argmax(probs)
    box = boxes[id]

    cv2.rectangle(frame_draw, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255, 0, 0), -1)

    # Add to frame list
    frames_tracked.append(cv2.resize(frame_draw, (360, 360), interpolation = cv2.INTER_AREA))
  return frames_tracked

from pyparsing.helpers import identbodychars
def crop_faces(frames):
  face_detector = MTCNN(margin=0, device=device)
  frames_crop = []
  for i, frame in enumerate(frames):
    print('\rTracking frame: {}'.format(i + 1), end='')

    # Detect faces
    boxes, probs = face_detector.detect(frame)

    # Draw faces
    frame_draw = frame.copy()
    #print(boxes)
    id = np.argmax(probs)
    #print(boxes, probs)

    if boxes is None:
      continue

    box = boxes[id]

    while np.all((box > 0)) == False:
      boxes = np.delete(boxes, id, 0)
      probs = np.delete(probs, id, 0)
      if (probs.size == 0):
        break
      id = np.argmax(probs)
      box = boxes[id]

    if probs.size == 0:
      continue

    #print(box)
    cv2.rectangle(frame_draw, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255, 0, 0), 6)
    face_frame = frame[int(box[1]):int(box[3]) ,int(box[0]): int(box[2])]
    #plt.imshow(frame_draw)

    frames_crop.append(cv2.resize(face_frame, (360, 360), interpolation = cv2.INTER_AREA))
  if (len(frames_crop) > 0):
    frames.append([frames_crop[-1]] * (32 - len(frames_crop)))
  return frames_crop

def save_video(frames, path):
  paths = path.split('/')
  paths[1] = paths[1] + '_cropped'
  crop_path = '/'.join(paths)
  out = cv2.VideoWriter(crop_path, cv2.VideoWriter_fourcc(*'mp4v'), 32, (360, 360))
  for frame in frames:
    out.write(frame)
  out.release()
  return True

# test_video = read_video('data/dfdc_train_part_1/aassnaulhq.mp4')
# crop_video = crop_faces(test_video)

# plt.imshow(crop_video[0])

# out = save_video(crop_video, 'data/dfdc_train_part_1/aassnaulhq.mp4')

# file_list = glob.glob('data/all_fake_deeperforensics_1/*.mp4')
# print(file_list)

file_list = glob.glob('data/all_real_deeperforensics_2/*.mp4')
#print(file_list)
dem = 0
for video_path in file_list:
  name_path = video_path.split('/')
  if os.path.isfile('data/all_real_deeperforensics_2_cropped/' + name_path[2]):
    print('inorge')
    continue
  print(video_path)
  video = read_video(video_path)
  crop_video = crop_faces(video)
  if len(crop_video) == 0:
    print('inorge ' + name_path[2])
    continue

  out = save_video(crop_video, video_path)
  print('Saved succesfully ' + name_path[2])
  dem += 1
  print(dem)

